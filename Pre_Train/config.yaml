batch_size: 32
epochs: 15
eval_every_n_epochs: 1
fine_tune_from: None
log_every_n_steps: 50
gpu: cuda:0

optim:
  optimizer: Adam
  lr: 0.00001
  weight_decay: 1e-6

model: 
  atom_fea_len: 64
  h_fea_len: 64
  n_conv: 3
  n_h: 1

dataset:
  root_dir: Dataset/MP_DATA_post/
  max_num_nbr: 12
  radius: 8
  dmin: 0
  step: 0.2
  random_seed: 666

dataloader:
  val_ratio: 0.2
  num_workers: 0

loss1:  
  batch_size: 32
  temperature: 0.1
  use_cosine_similarity: True

loss:
  embed_size: 128
  lambd: 0.0051
  batch_size: 32
